nsml run -d owt_tensor -c 2 -g 2 --memory "40G" -m "transformer original owt" -e run_language_modeling.py -a "--tokenizer_name=bert-base-uncased --fp16 --output_dir=output --do_train --train_data_file=./owt_tensor --model_type=electra --per_device_train_batch_size=64 --num_train_epoch=40 --save_steps=10000 --max_steps=1000000 --block_size=128"

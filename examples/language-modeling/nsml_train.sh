nsml run -d owt_tensor_nsml -c 2 -g 3 --memory "150G" -m "transformer original owt" -e run_language_modeling.py -a "--tokenizer_name=bert-base-uncased --fp16 --output_dir=output --do_train --train_data_file=/data/owt_tensor_nsml/train --model_type=electra --per_device_train_batch_size=64 --num_train_epoch=40 --save_steps=10000 --max_steps=1000000 --block_size=128"
